import numpy as np
import pandas as pd
import ALoNe
import xml.etree.ElementTree as ET
import tqdm
import glob
import os
import random

"""
Utility functions to read in segmentations from different sources (e.g. TGMM (McDole et al 2018)).
"""

def read_multiple_tgmm(path):
    """
    Read multiple tgmm segmentation results and return as pd.DataFrame.

    Convenience function using `read_tgmm()`. In addition to the columns specified in that function, this df has a
    column 'sample' that contains the filename of the .xml (without the extension).
    :param path: str or os.path object, path to folder containing the tgmm .xml files
    :return: df
    """
    seg_files = glob.glob(path + '*.xml')
    dfs = []
    for seg_file in seg_files:
        name = os.path.basename(seg_file).split('.')[0]
        sdf = ALoNe.SegmentationIO.read_tgmm(seg_file)
        sdf['sample'] = name
        dfs.append(sdf)
    df = pd.concat(dfs)
    df.reset_index(drop=True, inplace=True)
    df['cell id'] = df.index + 1
    return df


def read_tgmm(xml_path, labels=None):
    """
    Read single cell segmentation results from TGMM (McDole et al., Cell, 2018) and return as pandas DataFrame.

    Input is a folder containing the .xml files generated by TGMM. Those have the default name
    'GMEMfinalResult_frame????.xml' (???? = frame number, e.g. 0001).

    The returned DataFrame contains single cells as rows and their specifics as columns. The latter are:
    * index: running index generated by the DataFrame
    * cell id: unique id of a cell in a given frame
    * parent id: cell id of parent cell in previous frame. -1 indicates the beginning of a track.
    * split score: confidence level for the correct tracking of this particular object. A value of 0 indicates very low
        confidence and a value of 5 indicates very high confidence. Sorting elements by confidence level can guide the
        user in the data curation process and facilitate more effective editing of the TGMM results.
    * nu: cell shape prior
    * beta: cell position prior
    * alpha: track consistency prior
    * x, y, z: cartesian coordinates of the nucleus.
    * precision matrix: np.array, inverse of the covariance matrix of the multivariate Gaussian distribution used for
        fitting the nucleus. Encodes nuclear shape (eigenvectors = main axes, 1/eigenvalues ~ length of main axes).
    * frame: number of the time frame

    :param xml_path: str, path to a TGMM generated .xml file
    :param labels: dict, key=column name, val=value of the column (can be single or list)
    :return: pd.DataFrame, containing individual cells per row and corresponding information as mentioned above.
    """
    names = ['cell id TGMM', 'parent id TGMM', 'split score', 'nu', 'beta', 'alpha', 'x', 'y', 'z',
             'precision matrix']
    tree = ET.parse(xml_path)
    root = tree.getroot()
    l = []
    for cell in root.iter('GaussianMixtureModel'):
        try:
            id = int(cell.attrib['id'])
            parent_id = int(cell.attrib['parent'])
            split_score = float(cell.attrib['splitScore'])
            nu = float(cell.attrib['nu'])
            beta = float(cell.attrib['beta'])
            alpha = float(cell.attrib['alpha'])
            xyz = np.array(cell.attrib['m'].split(' ')[0:3], dtype=np.float)
            x, y, z = tuple(xyz)
            p_mtrx = np.array(cell.attrib['W'].split(' ')[0:-1], dtype=np.float).reshape((3, 3))
            if np.any(p_mtrx == np.inf):
                continue
        except ValueError:
            continue
        l.append([id, parent_id, split_score, nu, beta, alpha, x, y, z, p_mtrx])
    out = pd.DataFrame(l, columns=names)
    if labels is not None:
        for key, val in labels.items():
            out[key] = val
    out['cell id'] = out['cell id TGMM'] + 1
    return out

def read_MaMuT(xml_path, disable_status=False):
    """
    Read TGMM segmentation and tracking results from MaMuT .xml file.

    Not really used anymore.
    The returned DataFrame contains single cells as rows and their specifics as columns. The latter are:
    * cell id: integer, unique cell identifier.
    * cell name: str., similar to cell id
    * radius: float, approximation of the nuclear radius
    * quality: float, quality of the segmentation and tracking
    * frame: integer, number of the frame contatining the cell
    * x, y, z: float, carrtesian coordiantes of the cell
    * division time: int, frames since the cell divided last
    :param xml_path: string, path to the MaMuT .xml file.
    :param disable_status: boolean, show status bar labeled 'Reading MaMuT'
    :return: pd.DataFrame, containing individual cells per row and corresponding information as mentioned above.
    """
    tree = ET.parse(xml_path)
    n_frames = len(tree.findall('SpotsInFrame'))
    root = tree.getroot()
    columns = ['cell id', 'cell name', 'radius', 'quality', 'frame', 'x', 'y', 'z', 'division time']
    l = []
    pbar = tqdm.tqdm(total=n_frames, desc='Reading MaMuT', disable=disable_status)
    for child in root.iter('SpotsInFrame'):
        pbar.update(1)
        for spot in child.iter('Spot'):
            id = int(spot.attrib['ID'])
            name = spot.attrib['name']
            radius = float(spot.attrib['RADIUS'])
            quality = float(spot.attrib['QUALITY'])
            frame = int(spot.attrib['FRAME'])
            x = float(spot.attrib['POSITION_X'])
            y = float(spot.attrib['POSITION_Y'])
            z = float(spot.attrib['POSITION_Z'])
            if 'CELL_DIVISION_TIME' in spot.attrib:
                division_time = int(float(spot.attrib['CELL_DIVISION_TIME']))
            else:
                division_time = np.NaN
            l.append([id, name, radius, quality, frame, x, y, z, division_time])
    pbar.close()
    return pd.DataFrame(l, columns=columns)

def read_imaris_csv(csv_path):
    """
    Read Imaris segmentation from .csv file (generated by Imaris).

    The returned DataFrame contains single cells as rows and their specifics as columns. The latter are:
    * x, y, z: float, cartesian coordinates of the cell (in micrometers and in the Imaris coordinate system - this might
        not be the array coordinate system).
    * frame: integer, number of the frame contatining the cell.
    :param csv_path: string, path to the .csv file
    :return: pd.DataFrame, containing individual cells per row and corresponding information as mentioned above.
    """
    df = pd.read_csv(csv_path, skiprows=3)
    df = df.drop(columns=['Unit', 'Category', 'Collection','ID', 'Unnamed: 8'], index=1)
    df = df.rename(columns={'Cell Position X': 'x',
                            'Cell Position Y': 'y',
                            'Cell Position Z': 'z',
                            'Position X': 'x',
                            'Position Y': 'y',
                            'Position Z': 'z',
                            'Time': 'frame'})
    return df


def make_tracks(df, disable_status=False):
    # df has column names
    # * cell id
    # * frame
    # * parent id
    #   * pid = -1: start of the track
    #   * pid = -2: parent cell not found
    unique_tid = 0
    # tids = []
    pbar = tqdm.tqdm(total=df.index.max(), desc='Making tracks', disable=disable_status)

    frames = df['frame'].values
    cell_ids = df['cell id TGMM'].values
    parent_ids = df['parent id TGMM'].values
    track_ids = np.empty(len(cell_ids), dtype=int)
    unique_parent_ids = np.empty(len(cell_ids), dtype=int)

    for i in range(len(cell_ids)):
        pbar.update(1)
        if parent_ids[i] == -1:
            # df.at[i, 'track id'] = tid
            unique_parent_ids[i] = -1
            tid = unique_tid
            unique_tid += 1
        else:
            pid = parent_ids[i]
            frame = frames[i]
            try:
                mask1 = np.in1d(frames, [frame - 1])
                mask2 = np.in1d(cell_ids, [pid])
                full_mask = np.logical_and(mask1, mask2)
                parent_index = np.where(full_mask)
                tid = track_ids[parent_index][0]
                unique_parent_ids[i] = parent_index[0]
            except IndexError:
                unique_parent_ids[i] = -2
                tid = -1
        # df.at[i, 'track id'] = tid
        # print(tid)
        track_ids[i] = tid
    df['track id'] = track_ids
    df['parent id'] = unique_parent_ids
    df['cell id'] = np.arange(len(cell_ids), dtype=int)
    return df

# def connect_cells()


def read_tgmm_from_folders(tgmm_path):
    """
    Generate pd.DataFrame from TGMM segmentation output directly.

    Automatically reads in TGMM segmentations from the GMEMtracking3D folders generated by TGMM.
    Individual samples are differentiated by the 'sample' column, which contains the original image file name.
    !! No other folder/files than the TGMM output can be in the subdirectories of tgmm_path.

    :param tgmm_path: str, path: folder containing at least one GMEMtracking3D... folder
    :return: pd.DataFrame
    """
    l = []
    walk = os.walk(tgmm_path)
    next(walk)
    for entry in walk:
        p, d, f = entry
        log = pd.read_csv(os.path.join(p, f[0]), skiprows=2, delimiter='=', header=None, index_col=0)
        name = log.loc['imgFilePattern'].values[0].split('\\')[-1]
        p, d, f = next(walk)
        f.sort()
        _sdf = ALoNe.SegmentationIO.read_tgmm(os.path.join(p, f[-1]), {'sample': name})
        l.append(_sdf)
    df = pd.concat(l)
    df.reset_index(inplace=True, drop=True)
    return df


def generate_random_cell_id_prefix(n=4):
    """
    Generate a random string of length n.

    Used symbols are lower case letters, upper case letters and special characters.
    Generated sting is unique in 1:10,000,000 for n=4; 57**n
    :param n: int, length of string
    :return: str, random string
    """
    np.random.seed()
    prf = [chr(random.randint(65, 122)) for i in range(n)]
    return ''.join(prf)
